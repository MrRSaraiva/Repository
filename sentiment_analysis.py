# -*- coding: utf-8 -*-
"""sentiment_analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sWfvkoVRcWloEbaKM2-ahjR6QDEBz_Do
"""

# This is a Python script for the sentiment analysis of product reviews

# Import libraries
import numpy as np
import pandas as pd
import spacy
from textblob import TextBlob

# Note: I used Google Colab for this project and was unable to load files. After researching, this is the solution I could find to load the csv file.
#       I had to shorten the data due to the max upload restriction on GitHub.

# Import csv file with reviews
amazon_reviews = pd.read_csv('https://raw.githubusercontent.com/MrRSaraiva/Repository/c2023dcb9fc3044015a59b0b7e957ea240769046/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_SmallerSize.csv')

# Import language model from spaCy
nlp = spacy.load('en_core_web_sm')

# Preview of the dataset
amazon_reviews.head()

# Extract only the reviews column
cleaned = amazon_reviews[['reviews.text']]
cleaned.head()

# Check for null values
cleaned.isnull().sum()

# Remove null values (if needed)
cleaned.dropna(inplace = True, axis = 0)

# Getting only the reviews
text = cleaned['reviews.text']
text

# Function to preprocess text
def preprocess(text):

  # Tokenizing text, converting to lower case and removing whitespaces.
  doc = nlp(text.lower().strip())

  # Removing stop words and punctuation, lemmatising and converting text to lower case
  processed = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]

  # Creating a sentence by joining the processed words separated by whitespaces
  return ' '.join(processed)

# Using the .apply method to enable the use of series in the function above
cleaned['processed.text'] = text.apply(preprocess)

# Extracting the values inside the series object
data = cleaned['processed.text'].values
print(data)

# Checking if the data object is iterable
for item in data:
  print(item)

# Creating a function to analyse text polarity
def analyse_polarity(text):

    # Preprocess the text with spaCy
    doc = nlp(text)

    # Analyse sentiment with TextBlob
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity

    return polarity

# Checking polarity of a review

# For the polarity of a single review within the data, specify the index of the review within [] as below
chosen_review = data[4]

# Printing review and its polarity result
print(f"Review - ", chosen_review, "\n\nPolarity ", analyse_polarity(chosen_review))

# Comparing reviews

### Note: The instructions for this task specifically mentioned we should use the 'en_core_web_sm' model which I am using.
#         I believe, however, that the use of a larger language model such as the 'en_core_web_md' could be beneficial here.

# Defining reviews to compare - Simply change the index value to compare a different review (The maximum index value is [940])
review1 = data[0]
review2 = data[1]

# Applying the similarity() method
similarity = nlp(review2).similarity(nlp(review1))

# Printing both sentences and the similarity result
print(f"Review 1 - ", review1, "\n\nReview 2 - ", review2, "\n")
print(f"Similarity - ", similarity, "\n")

# Creating a list to store the sorted results of polarity scores
sentiments = []

# Iterating over each item in the data and sort the items by polarity score
for item in data:

  # Using the function defined above to attribute a polarity score to each item in the data
  polarity_score = analyse_polarity(item)

  # Sorting items as positive, negative or neutral according to their polarity score
  if polarity_score > 0:
    sentiment = 'positive'
  elif polarity_score < 0:
    sentiment = 'negative'
  elif polarity_score == 0:
    sentiment = 'neutral'

  # Adding the result of each item to the sentiments list created above
  sentiments.append(sentiment)

# Displays sentiments
sentiments

# Counting polarity results
positive_count = sentiments.count('positive')
negative_count = sentiments.count('negative')
neutral_count = sentiments.count('neutral')

print(positive_count)
print(negative_count)
print(neutral_count)

# Counting the total of all reviews to calculate percentages below
total = len(sentiments)

# Turning results into percentages
positive_perc = (positive_count / total) * 100
negative_perc = (negative_count / total) * 100
neutral_perc = (neutral_count / total) * 100

# Printing results of sentiment analysis (displaying 2 decimal places)
print("Sentiment results:\n\n")
print(f"Positive percentage: {positive_perc:.2f}%")
print(f"Negative percentage: {negative_perc:.2f}%")
print(f"Neutral percentage: {neutral_perc:.2f}%")